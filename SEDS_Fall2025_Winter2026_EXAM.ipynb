{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG src=\"figures/logo-esi-sba.png\" WIDTH=300 height=\"100\" ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Software Engineering for Data Science \n",
    "## Final Exam: Fall 2025-Winter 2026\n",
    "## Exam Duration: 02:30 Hours\n",
    "\n",
    "*By Dr. Belkacem KHALDI (b.khaldi@esi-sba.dz)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Revised Exam Instruction:**\n",
    "\n",
    "During this exam, you may consult only your lecture notes, lab materials, and personal documentation. The use of large language models (LLMs), whether offline or online, is strictly prohibited. Any violation of this policy constitutes academic misconduct and will result in sanctions, including a grade of zero for the affected exercise.\n",
    "\n",
    "Adherence to these rules is required to ensure fairness and integrity in the assessment process. Direct any questions or concerns to the exam proctor or instructor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Note: Exam Requirements & Continuous Evaluation Grade**\n",
    "\n",
    "This exam consists of two mandatory challenges. Both challenges must be completed to a satisfactory standard to pass the exam.\n",
    "\n",
    "However, for your **Final Continuous Evaluation Grade**, only **one** of the two challenges will be formally assessed and contribute to your grade. You must choose which challenge you wish to be considered for this evaluation.\n",
    "\n",
    "Please review the options below and decide which challenge you would like to submit for your continuous evaluation grade.\n",
    "\n",
    "---\n",
    "\n",
    "### **Continuous Evaluation Challenge Options (Choose One)**\n",
    "\n",
    "**Option 1: Challenge 1: Data Wrangling, Scraping, and Cleaning for Strategic HRST Planning**\n",
    "*   **Focus:** This option assesses your skills in advanced data ingestion, transformation, and database manipulation. This may include ingesting data from quering a database schema (e.g., a snowflake schema), and integrating data from different resources like  web scraping, csv, and json files.\n",
    "\n",
    "**Option 2: Challenge 2: Interactive Web Application Development**\n",
    "*   **Focus:** This option assesses your ability to apply the cleaned data to build a user-facing analytical tool. You will develop an interactive web application using either **Gradio** or **Streamlit** to visualize key population metrics, as detailed in the \"Developing a Web Application for the African Union\" challenge. **Bonus points will be awarded for applications built with Gradio.**\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "1.  **For the Exam:** Complete both challenges to the best of your ability.\n",
    "2.  **For Your Final Continous Evaluation Grade:** Decide which of the two challenges (Option 1 or Option 2) you want to be formally graded.\n",
    "3.  **Submission:** Clearly state your choice (e.g., \"I choose Option 2 for my continuous evaluation grade.\") in the comments of your final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I choose Option 1 for my continuous evaluation grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Challenge 1: Data Wrangling, Scraping, and Cleaning for Strategic HRST Planning**\n",
    "\n",
    "### **Objective:**\n",
    "You have just taken a role as a Data Scientist at the Department of Human Resources, Science and Technology (HRST) within the African Union Organization. Your task is to gather and clean data related to population statistics across the continent. This data is crucial for informing strategic planning in human capital development and potential technological infrastructure deployment. You will need to integrate data from various sources, including web scraping for specific subregions, querying a central database, and processing CSV and json files. Subsequently, you will perform necessary data cleaning and analysis to ensure the quality and usability of the data for policy-making.\n",
    "\n",
    "### **Key Points to Note:**\n",
    "- **Comprehensive Data Integration:** \n",
    "   You should integrate data from CSV and json files, a SQLite database, and web scraping into one unified DataFrame.\n",
    "\n",
    "- **Data Cleaning:**\n",
    "    Emphasis should be placed on cleaning the data to ensure consistency, accuracy, and usability for high-level strategic analysis.\n",
    "\n",
    "- **Handling Failures:** \n",
    "   You are encouraged to perform data integration to the best of your ability, even if you fail with some of the requirements of the followining parts. The final cleaned CSV file should include data from the successfully ingested sources, while clearly documenting any issues faced with the other sources in the notebook. You should save the final successful cleaned CSV file as `resources/<your_name>_HRST_Africa_Population_Cleaned.csv` (e.g.:`bkhaldi_HRST_Africa_Population_Cleaned.csv`), which will be used later for `Challenge 02: Developing a Gradio/Streamlit Web Application for the HRST Department`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1: Data Ingestion from SQLite Database**\n",
    "\n",
    "**Task:** Connect to the provided SQLite database (`resources/db/population_star.db`) and extract the appropriate data. This database contains historical data for thre sub african regions:`Eastern Africa`,`Western Africa`, and `Middle Africa`  that will serve as a baseline for the HRST analysis.\n",
    "\n",
    "**Requirements:**\n",
    "*   The database is a dementinal database with a Star Schema and contains the following tables `FactPopulation`, `DimGeography`, and `DimTime`.\n",
    "*   The resulting DataFrame should be named `df_db`.\n",
    "\n",
    "<figure>\n",
    "  <IMG src=\"figures/sqllite_db_diagram.png\"  ALIGN=\"center\">\n",
    "</figure>\n",
    "\n",
    "#### Data Dictionary: Star Schema Tables\n",
    "\n",
    "This section provides detailed explanations for each column in the star schema database tables to ensure a clear understanding of the data structure.\n",
    "\n",
    "##### **FactPopulation**\n",
    "\n",
    "The central fact table containing all numerical population metrics. The grain is one row per country per year.\n",
    "\n",
    "| Column Name | Description |\n",
    "|---|---|\n",
    "| `FactKey` | Surrogate primary key for the fact table. |\n",
    "| `TimeKey` | Foreign key linking to the `DimTime` table. |\n",
    "| `GeographyKey` | Foreign key linking to the `DimGeography` table. |\n",
    "| `Population` | Total population for the country in a given year. |\n",
    "| `YearlyChange` | Absolute change in total population over the preceding five-year period (or last year for 2025 data). |\n",
    "| `YearlyPercentChange` | Percentage change in total population over the preceding five-year period (or last year for 2025 data). |\n",
    "| `Migrants` | The average annual number of immigrants minus the number of emigrants over the preceding five-year period. A negative number indicates more emigrants. |\n",
    "| `MedianAge` | The age that divides the population into two numerically equal groups. |\n",
    "| `FertilityRate` | The average number of children an average woman will have during her reproductive period (15 to 49 years old). |\n",
    "| `Density` | Population density, expressed as people per square kilometer (P/Km²). |\n",
    "| `UrbanPopPercent` | Urban population as a percentage of the total population. |\n",
    "| `UrbanPopulation` | Population living in areas classified as urban. |\n",
    "| `WorldSharePercent` | The country's total population as a percentage of the total World Population. |\n",
    "| `GlobalRank` | The country's rank in the list of all countries worldwide ranked by population. |\n",
    "| `WorldPopulation` | The total World Population as of July 1 of the year indicated. |\n",
    "| `WorldYearlyChange` | Absolute change in total World Population over the preceding five-year period. |\n",
    "| `WorldYearlyPercentChange` | Percentage change in total World Population over the preceding five-year period. |\n",
    "\n",
    "##### **DimGeography**\n",
    "\n",
    "The dimension table containing geographical attributes.\n",
    "\n",
    "| Column Name | Description |\n",
    "|---|---|\n",
    "| `GeographyKey` | Surrogate primary key for the geography dimension. |\n",
    "| `CountryName` | The name of the country. |\n",
    "| `Continent` | The continent the country belongs to. |\n",
    "| `Subregion` | The subregion within the continent. |\n",
    "\n",
    "##### **DimTime**\n",
    "\n",
    "The dimension table containing time-related attributes.\n",
    "\n",
    "| Column Name | Description |\n",
    "|---|---|\n",
    "| `TimeKey` | Surrogate primary key for the time dimension. |\n",
    "| `Year` | The calendar year. |\n",
    "| `Decade` | The decade (e.g., 2020). |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_path = 'resources/db/population_star.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    dt.Year,\n",
    "    dg.CountryName,\n",
    "    dg.Continent,\n",
    "    dg.Subregion,\n",
    "    fp.Population,\n",
    "    fp.YearlyChange,\n",
    "    fp.YearlyPercentChange,\n",
    "    fp.Migrants,\n",
    "    fp.MedianAge,\n",
    "    fp.FertilityRate,\n",
    "    fp.Density,\n",
    "    fp.UrbanPopPercent,\n",
    "    fp.UrbanPopulation,\n",
    "    fp.WorldSharePercent,\n",
    "    fp.GlobalRank,\n",
    "    fp.WorldPopulation,\n",
    "    fp.WorldYearlyChange,\n",
    "    fp.WorldYearlyPercentChange\n",
    "FROM FactPopulation fp\n",
    "JOIN DimGeography dg ON fp.GeographyKey = dg.GeographyKey\n",
    "JOIN DimTime dt ON fp.TimeKey = dt.TimeKey\n",
    "\"\"\"\n",
    "\n",
    "df_db = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"Database records loaded: {len(df_db)}\")\n",
    "print(df_db.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2: Data Ingestion from CSV and json Files**\n",
    "\n",
    "**Task:** Read and combine data from multiple CSV and json files located in the `resources/Southern_Africa/` directory. These files were manually compiled by field officers in the **Southern_Africa** subregion and need to be integrated into our central dataset.\n",
    "\n",
    "**Requirements:**\n",
    "*   Parse each CSV and json file into a DataFrame.\n",
    "*   Combine appropriate individual DataFrames into a single appropriate DataFrame named `df_csv` for csv dataframes and `df_json` for json dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "csv_files = [\n",
    "    'resources/Southern_Africa/csv/southern_africa_eswatini.csv',\n",
    "    'resources/Southern_Africa/csv/southern_africa_lesotho.csv',\n",
    "    'resources/Southern_Africa/csv/southern_africa_namibia.csv',\n",
    "    'resources/Southern_Africa/csv/southern_africa_south_africa.csv'\n",
    "]\n",
    "\n",
    "csv_dataframes = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    csv_dataframes.append(df)\n",
    "\n",
    "df_csv = pd.concat(csv_dataframes, ignore_index=True)\n",
    "\n",
    "json_file = 'resources/Southern_Africa/json/southern_africa_botswana.json'\n",
    "with open(json_file, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "df_json = pd.DataFrame(json_data)\n",
    "\n",
    "print(f\"CSV records loaded: {len(df_csv)}\")\n",
    "print(f\"JSON records loaded: {len(df_json)}\")\n",
    "print(df_csv.head())\n",
    "print(df_json.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3: Data Ingestion from Web Scraping**\n",
    "\n",
    "**Task:** Scrape the latest available detailed population data for every country within the **Northern Africa** subregion from the Worldometers local website (available in `resources\\wordometer` folder). This requires a two-step automated scraping process to gather comprehensive historical data for this key region.\n",
    "\n",
    "**Note: Offline Protocol (FILE)**\n",
    "\n",
    "**For offline scraping**, where the source is a local HTML file, the protocol must be changed to `file://` rather than the `http://` protocol. This protocol instructs the web browser to bypass the internet entirely. Instead, it directly accesses the local file system of the computer on which the script is running. The browser then opens and renders the specified file.\n",
    "\n",
    "- **For a Windows User:** The script will construct a full path like `C:\\Users\\YourName\\your_project_folder\\data\\target.htm`. The final URL the browser opens will be `file:///C:/Users/YourName/your_project_folder/data/target.htm`.\n",
    "- **For a Linux/macOS User:** The script will construct a full path like `/home/yourname/your_project_folder/data/target.htm`. The final URL will be `file:///home/yourname/your_project_folder/data/target.htm`.\n",
    "\n",
    "A working guide example using selenium to access an offline web page:\n",
    "\n",
    "``` python\n",
    "from selenium import webdriver\n",
    "import os\n",
    "\n",
    "# Initialize the WebDriver (example for Chrome)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Define the relative path to your HTML file\n",
    "# Use forward slashes (or double backslashes on Windows)\n",
    "relative_path = \"Users\\\\YourName\\\\your_project_folder\\\\data\\\\target.htm\"\n",
    "\n",
    "# Get the current working directory and join with the relative path\n",
    "# os.path.join handles the correct slash for the OS\n",
    "abs_file_path = os.path.join(os.getcwd(), relative_path)\n",
    "\n",
    "# Add the 'file:///' protocol prefix (three slashes are for the protocol, \n",
    "# and the path starts with one more if it's the root on Linux/macOS)\n",
    "url = \"file:///\" + abs_file_path\n",
    "\n",
    "# On Windows, you might need to adjust for the drive letter prefix\n",
    "# if using an older Selenium version, but the 'file:///' prefix \n",
    "# with the output of os.path.join generally works across platforms.\n",
    "\n",
    "# Navigate to the local file\n",
    "driver.get(url)\n",
    "\n",
    "# Proceed with your web scraping actions\n",
    "print(f\"Opened URL: {driver.current_url}\")\n",
    "# ... your scraping code here ...\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Requirements:**\n",
    "1.  **Step 1: Extract Country Links:** First, visit the Northern Africa subregional page (`resources\\wordometer\\northern-africa-population.htm`) and scrape the list of all countries. For each country, extract its name and navigate to its corresponding link to scrap its detailed population page (see Algeria page as example: `resources\\wordometer\\northan-africa-countries\\algeria-population.htm`).\n",
    "2.  **Step 2: Iterate and Scrape Details:** Next, write a loop that iterates through the list of country links extracted in Step 1. For each link, navigate to the country's detailed page and scrape the full historical population data table.\n",
    "3.  **Data Combination:** Combine the scraped data from all countries into a single, unified DataFrame named `df_web`.\n",
    "4.  **Data Cleaning:** After scraping, ensure the DataFrame is clean while adding the required columns such as `continent` and `subregion`, and standardize column names to match the database DataFrame\n",
    "\n",
    "\n",
    "<figure>\n",
    "  <IMG src=\"figures/north_africa_subregion_webscraping.png\"  ALIGN=\"center\">\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "  <IMG src=\"figures/algeria_example_detailed_info_to_scrap.png\"  ALIGN=\"center\">\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "main_page_path = os.path.abspath('resources/wordometer/northern-africa-population.htm')\n",
    "main_url = 'file:///' + main_page_path\n",
    "\n",
    "driver.get(main_url)\n",
    "time.sleep(2)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "country_table = soup.find('table')\n",
    "country_links = []\n",
    "\n",
    "if country_table:\n",
    "    rows = country_table.find_all('tr')[1:]\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) > 0:\n",
    "            link = cells[0].find('a')\n",
    "            if link and link.get('href'):\n",
    "                country_name = link.text.strip()\n",
    "                href = link.get('href')\n",
    "                country_links.append({'name': country_name, 'href': href})\n",
    "\n",
    "all_country_data = []\n",
    "\n",
    "for country in country_links:\n",
    "    country_page_path = os.path.abspath(f'resources/wordometer/northan-africa-countries/{country[\"href\"]}')\n",
    "    country_url = 'file:///' + country_page_path\n",
    "    \n",
    "    driver.get(country_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    for table in tables:\n",
    "        headers = [th.text.strip() for th in table.find_all('th')]\n",
    "        if 'Year' in headers and 'Population' in headers:\n",
    "            rows = table.find_all('tr')[1:]\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) >= len(headers):\n",
    "                    row_data = {headers[i]: cells[i].text.strip() for i in range(len(headers))}\n",
    "                    row_data['CountryName'] = country['name']\n",
    "                    all_country_data.append(row_data)\n",
    "            break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df_web = pd.DataFrame(all_country_data)\n",
    "df_web['Continent'] = 'Africa'\n",
    "df_web['Subregion'] = 'Northern Africa'\n",
    "\n",
    "print(f\"Web scraped records: {len(df_web)}\")\n",
    "print(df_web.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 4: Data Integration and Cleaning**\n",
    "\n",
    "**Task:** Now, your goal is to combine all the DataFrames that you have ingested from different sources into a single, clean, and unified DataFrame named `final_africa_df`.\n",
    "\n",
    "This is a critical step in any data project. You must assess the data from each source, identify inconsistencies, and apply the necessary transformations to create a reliable and coherent dataset.\n",
    "\n",
    "**Documentation is Key:**\n",
    "You are expected to document your entire process. In the code cell below and in subsequent Markdown cells, you must clearly explain:\n",
    "*   **What problems** you identified in the data (e.g., mismatched columns, incorrect data types, missing values, duplicates).\n",
    "*   **What steps** you took to clean and preprocess the data.\n",
    "*   **Why** you chose to perform each step. Your justification is as important as the code itself.\n",
    "\n",
    "---\n",
    "**Final Output:**\n",
    "*   Save your final, cleaned DataFrame to the path `resources/<your_name>_HRST_Africa_Population_Cleaned.csv`.\n",
    "*   This file will be the official dataset used in the next challenge for developing the Gradio web application.\n",
    "\n",
    "**Validation:**\n",
    "*   Display the `head()` of your final DataFrame.\n",
    "*   Use the `.info()` method to show a summary of the columns, data types, and non-null values.\n",
    "*   Print the total number of unique countries and the total number of rows in your final dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_csv, df_json], ignore_index=True)\n",
    "\n",
    "column_mapping = {\n",
    "    'Yearly % Change': 'YearlyPercentChange',\n",
    "    'Yearly Change': 'YearlyChange',\n",
    "    'Migrants (net)': 'Migrants',\n",
    "    'Median Age': 'MedianAge',\n",
    "    'Fertility Rate': 'FertilityRate',\n",
    "    'Density (P/Km²)': 'Density',\n",
    "    'Urban Pop %': 'UrbanPopPercent',\n",
    "    'Urban Population': 'UrbanPopulation',\n",
    "    \"Country's Share of World Pop\": 'WorldSharePercent',\n",
    "    'World Population': 'WorldPopulation',\n",
    "    'Algeria Global Rank': 'GlobalRank'\n",
    "}\n",
    "\n",
    "df_web_cleaned = df_web.rename(columns=column_mapping)\n",
    "\n",
    "def clean_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace(',', '').replace('%', '').strip()\n",
    "        try:\n",
    "            return float(value)\n",
    "        except:\n",
    "            return None\n",
    "    return value\n",
    "\n",
    "numeric_columns = ['Population', 'YearlyChange', 'YearlyPercentChange', 'Migrants', \n",
    "                   'MedianAge', 'FertilityRate', 'Density', 'UrbanPopPercent', \n",
    "                   'UrbanPopulation', 'WorldSharePercent', 'GlobalRank', \n",
    "                   'WorldPopulation', 'WorldYearlyChange', 'WorldYearlyPercentChange']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df_web_cleaned.columns:\n",
    "        df_web_cleaned[col] = df_web_cleaned[col].apply(clean_numeric)\n",
    "    if col in df_combined.columns:\n",
    "        df_combined[col] = df_combined[col].apply(clean_numeric)\n",
    "\n",
    "if 'Year' in df_web_cleaned.columns:\n",
    "    df_web_cleaned['Year'] = pd.to_numeric(df_web_cleaned['Year'], errors='coerce')\n",
    "if 'Year' in df_combined.columns:\n",
    "    df_combined['Year'] = pd.to_numeric(df_combined['Year'], errors='coerce')\n",
    "\n",
    "final_africa_df = pd.concat([df_db, df_combined, df_web_cleaned], ignore_index=True)\n",
    "\n",
    "final_africa_df = final_africa_df.drop_duplicates(subset=['Year', 'CountryName'], keep='first')\n",
    "final_africa_df = final_africa_df.sort_values(['CountryName', 'Year']).reset_index(drop=True)\n",
    "\n",
    "output_path = 'resources/student_HRST_Africa_Population_Cleaned.csv'\n",
    "final_africa_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Final dataset saved to {output_path}\")\n",
    "print(f\"\\nDataset shape: {final_africa_df.shape}\")\n",
    "print(f\"Unique countries: {final_africa_df['CountryName'].nunique()}\")\n",
    "print(f\"Year range: {final_africa_df['Year'].min()} - {final_africa_df['Year'].max()}\")\n",
    "print(\"\\nDataset info:\")\n",
    "print(final_africa_df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(final_africa_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Challenge 02: Developing a Web Application for the African Union**\n",
    "\n",
    "\n",
    "### **Objective:**\n",
    "Using your cleaned CSV file `resources/<your_name>_HRST_Africa_Population_Cleaned.csv`, you are tasked with creating an interactive web application. You may choose to build this application using either **Gradio** or **Streamlit**. This dashboard will serve as a tool for policymakers at the African Union's Department of Human Resources, Science and Technology (HRST) to explore and visualize key population metrics across the continent.\n",
    "\n",
    "### **Key Points to Note:**\n",
    "- **Platform Choice:** You may use either the `gradio` or `streamlit` library to build the web interface. **Bonus points will be awarded to students who successfully build their application using Gradio.**\n",
    "- **Interactivity:** Leverage your chosen framework's features (e.g., Gradio's event handlers or Streamlit's widget state) to make your visualizations dynamic. A user's selection from a dropdown should trigger an update in a plot or dataframe.\n",
    "- **Visualization Libraries:** Use libraries like `Plotly` and `Matplotlib` to generate your plots, which can then be rendered within your chosen framework's components.\n",
    "- **Code Organization:** Structure your code logically, with separate functions for each visualization or data processing task. This will make your application cleaner and easier to manage.\n",
    "\n",
    "---\n",
    "\n",
    "### **Required Functionalities:**\n",
    "\n",
    "Your web application should be organized into separate sections/pages and include the following features:\n",
    "\n",
    "**1. Data Overview:**\n",
    "*   Load and display the cleaned dataset (e.g., using `gr.DataFrame` or `st.dataframe`).\n",
    "*   Provide basic summary statistics of the dataset (e.g., total countries, years covered, etc.) using a markdown component.\n",
    "\n",
    "**2. Regional Population Analysis:**\n",
    "*   **Top Populous Countries:** Create a selection widget (e.g., `gr.Dropdown` or `st.selectbox`) to select a subregion. Based on the selection, display a bar chart showing the **top 5 most populous countries** within that subregion for the most recent year in the dataset.\n",
    "*   **Growth Leaders:** Using the same subregion selection, display another bar chart showing the **top 5 countries with the highest yearly population growth rate** for the most recent year.\n",
    "\n",
    "**3. Geographical and Temporal Visualization:**\n",
    "*   **Africa Population Map:** Generate a choropleth map of the African continent showing the population density for a user-selected year. Use a slider widget to allow the user to select the year and dynamically update the map.\n",
    "*   **Population Trend Race:** Create a bar chart race animation showing the population change of the top 10 most populous African countries over the years. This should be a key feature of your dashboard.\n",
    "*   **Hierarchical Sunburst Chart:** Generate an interactive Sunburst chart for a user-selected year. The chart should visualize the population hierarchy from **Continent -> Subregion -> Country**, where the size of each segment represents the population of that geographical area.\n",
    "\n",
    "**4. Demographic Distribution Analysis:**\n",
    "*   **Metric Distribution:** Use a selection widget to select a demographic metric (e.g., 'Median Age', 'Fertility Rate', 'Urban Pop %'). Display a histogram or KDE plot showing the probability distribution of that selected metric across all African countries for a user-selected year.\n",
    "\n",
    "**5. Advanced User Interaction:**\n",
    "*   **File Upload:** Include a file upload component that allows users to upload their own CSV file with the same column structure. The application should dynamically re-process the data and update all visualizations based on the newly uploaded file.\n",
    "*   **Multi-page Interface:** Organize all these functionalities into a clean, multi-page interface using the tabbing or navigation features of your chosen framework (e.g., `gr.Tabs()` or `st.tabs()`).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **End of Challenge**\n",
    "\n",
    "Please save your final application script (e.g., `<your_name>_hrst_population_dashboard.py`) and make sure your application is fully functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df = pd.read_csv('resources/student_HRST_Africa_Population_Cleaned.csv')\n",
    "\n",
    "def get_top_populous(subregion, df_input):\n",
    "    recent_year = df_input['Year'].max()\n",
    "    filtered = df_input[(df_input['Subregion'] == subregion) & (df_input['Year'] == recent_year)]\n",
    "    top5 = filtered.nlargest(5, 'Population')\n",
    "    fig = px.bar(top5, x='CountryName', y='Population', title=f'Top 5 Populous Countries in {subregion}')\n",
    "    return fig\n",
    "\n",
    "def get_top_growth(subregion, df_input):\n",
    "    recent_year = df_input['Year'].max()\n",
    "    filtered = df_input[(df_input['Subregion'] == subregion) & (df_input['Year'] == recent_year)]\n",
    "    top5 = filtered.nlargest(5, 'YearlyPercentChange')\n",
    "    fig = px.bar(top5, x='CountryName', y='YearlyPercentChange', title=f'Top 5 Growth Rates in {subregion}')\n",
    "    return fig\n",
    "\n",
    "def create_map(year, df_input):\n",
    "    filtered = df_input[df_input['Year'] == year]\n",
    "    fig = px.choropleth(filtered, locations='CountryName', locationmode='country names',\n",
    "                        color='Density', hover_name='CountryName',\n",
    "                        title=f'Population Density in Africa ({year})')\n",
    "    return fig\n",
    "\n",
    "def create_sunburst(year, df_input):\n",
    "    filtered = df_input[df_input['Year'] == year]\n",
    "    fig = px.sunburst(filtered, path=['Continent', 'Subregion', 'CountryName'],\n",
    "                      values='Population', title=f'Population Hierarchy ({year})')\n",
    "    return fig\n",
    "\n",
    "def create_distribution(metric, year, df_input):\n",
    "    filtered = df_input[df_input['Year'] == year]\n",
    "    fig = px.histogram(filtered, x=metric, title=f'{metric} Distribution ({year})')\n",
    "    return fig\n",
    "\n",
    "def process_upload(file):\n",
    "    if file is not None:\n",
    "        return pd.read_csv(file.name)\n",
    "    return df\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# HRST Population Dashboard\")\n",
    "    \n",
    "    with gr.Tab(\"Data Overview\"):\n",
    "        df_display = gr.DataFrame(df.head(100))\n",
    "        gr.Markdown(f\"Total Countries: {df['CountryName'].nunique()}, Years: {df['Year'].min()}-{df['Year'].max()}\")\n",
    "    \n",
    "    with gr.Tab(\"Regional Analysis\"):\n",
    "        subregion = gr.Dropdown(choices=df['Subregion'].unique().tolist(), label=\"Select Subregion\")\n",
    "        plot1 = gr.Plot()\n",
    "        plot2 = gr.Plot()\n",
    "        subregion.change(get_top_populous, inputs=[subregion, gr.State(df)], outputs=plot1)\n",
    "        subregion.change(get_top_growth, inputs=[subregion, gr.State(df)], outputs=plot2)\n",
    "    \n",
    "    with gr.Tab(\"Geographic Visualization\"):\n",
    "        year_slider = gr.Slider(minimum=int(df['Year'].min()), maximum=int(df['Year'].max()), \n",
    "                                step=1, label=\"Select Year\")\n",
    "        map_plot = gr.Plot()\n",
    "        year_slider.change(create_map, inputs=[year_slider, gr.State(df)], outputs=map_plot)\n",
    "    \n",
    "    with gr.Tab(\"Demographic Distribution\"):\n",
    "        metric_choice = gr.Dropdown(choices=['MedianAge', 'FertilityRate', 'UrbanPopPercent'], \n",
    "                                   label=\"Select Metric\")\n",
    "        year_choice = gr.Slider(minimum=int(df['Year'].min()), maximum=int(df['Year'].max()), \n",
    "                               step=1, label=\"Select Year\")\n",
    "        dist_plot = gr.Plot()\n",
    "        metric_choice.change(create_distribution, inputs=[metric_choice, year_choice, gr.State(df)], \n",
    "                           outputs=dist_plot)\n",
    "    \n",
    "    with gr.Tab(\"Upload Data\"):\n",
    "        file_upload = gr.File(label=\"Upload CSV\")\n",
    "        upload_status = gr.Textbox(label=\"Status\")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Submission Instructions:**\n",
    "\n",
    "- **Compression & Naming:** Compress all your solution into a single ZIP folder and name it using the following format:\n",
    "    `<full_name>_G<#n>_SEDS_EXAM_F25W26.zip`. Replace `<full_name>` with your full name and `<#n>` with your group number (e.g., G3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "websraping_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
